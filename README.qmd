---
format: gfm
bibliography: bibliography.bib
execute: 
  message: false
  warning: false
# knitr:
#   opts_chunk:
#     fig.path: "man/figures/README-"
# eval: false
default-image-extension: ""
---

# flowcluster

<!-- badges: start -->

[![R-CMD-check](https://github.com/Hussein-Mahfouz/flowcluster/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/Hussein-Mahfouz/flowcluster/actions/workflows/R-CMD-check.yaml)
[![codecov](https://codecov.io/gh/Hussein-Mahfouz/flowcluster/graph/badge.svg)](https://app.codecov.io/gh/Hussein-Mahfouz/flowcluster)
[![CRAN status](https://www.r-pkg.org/badges/version/flowcluster)](https://cran.r-project.org/package=flowcluster)

<!-- badges: end -->

The goal of flowcluster is to provide minimal functionality for clustering origin-destination (OD) pairs, representing desire lines (or flows). This includes:

1.  Creating distance matrices between OD pairs
2.  Passing distance matrices to a clustering algorithm

## Installation

You can install the released version of `flowcluster` from [CRAN](https://CRAN.R-project.org/package=flowcluster) with:

```{r}
#| eval=FALSE
install.packages("flowcluster")
```

And the development version from [GitHub](https://github.com/Hussein-Mahfouz/flowcluster) with:

```{r}
#| eval=FALSE
# install.packages("devtools")
devtools::install_github("Hussein-Mahfouz/flowcluster")
```


Load it as follows:

```{r}
library(flowcluster)
```

## Usage

The package provides a function to create a distance matrix from a data frame of OD pairs, and then pass that matrix to a clustering algorithm. The current distance matrix is an implementation of the flow distance and flow dissimilarity measures described in [@tao2016spatial]. See [@mahfouz2025flowcluster] for an example of how this package can be used to cluster flows for applied transportation research.

### Data preparation

First, load the flowcluster package and the sample data, and project it to a [projected](https://r.geocompx.org/spatial-class#projected-coordinate-reference-systems) coordinate reference system (CRS).\
This is important for accurate length calculations and spatial operations.

```{r}
library(tidyverse)
library(sf)
library(tmap)

# Load sample flow data and project to metric CRS (e.g., EPSG:27700)
flows_sf <- flows_leeds
flows_sf <- st_transform(flows_sf, "EPSG:27700")
```

Next, add a column containing the length (in meters) of each flow line.\
This step also checks that your data is in a projected CRS.

```{r}
# Add length (meters) to each flow line
flows_sf <- add_flow_length(flows_sf)
head(flows_sf, 5)
```

Filter out flows based on a minimum and maximum length. In the code below, we filter flows to keep only those between 1 and 20 kilometers.

```{r}
# Filter flows based on length (e.g., between 100 and 10000 meters)
flows_sf <- filter_by_length(flows_sf, length_min = 1000, length_max = 20000)
```

Then, extract start and end coordinates for each flow, and assign unique IDs.\
These are needed for subsequent distance calculations and clustering.

```{r}
# Add start/end coordinates and unique flow IDs
flows_sf <- add_xyuv(flows_sf)
head(flows_sf, 5)
```

### Distance Matrix calculation

Calculate a pairwise distance measure between all flows using their coordinates.\
You can adjust `alpha` and `beta` to change the relative importance of start and end locations in the clustering process.

```{r}
# Compute pairwise flow distances (fd and fds columns)
flows <- st_drop_geometry(flows_sf)
distances <- flow_distance(flows, alpha = 1, beta = 1)
```

Convert the long-format distance table to a matrix, which is required for clustering.

```{r}
# Create a distance matrix from the long-form distance data. Choose the column for distances you want to use.
# The 'fds' column is the flow dissimilarity measure, and the 'fd' column is the flow distance measure.
dmat <- distance_matrix(distances, distance_col = "fds")
# check 1st couple of rows columns of the distance matrix
head(dmat[1:2, 1:2])
```

### Clustering

Prepare a weight vector, typically based on a "count" column (number of trips, etc).\
If your data does not have a "count" column, you can add one with `flows$count <- 1`. Weights are very handy, otherwise our matrix would be huge, as we would have to replicate each OD pair n times depending on the number of observations between them. Unfortunately, there is no out-of-the-box support for adding weights in other clustering algorithms such as `hdbscan` or `optics`, so we will use {[dbscan](https://github.com/mhahsler/dbscan)} for now, which does support weights.

```{r}
# Prepare weights for each flow (here we use the count column)
wvec <- weight_vector(dmat, flows, weight_col = "count")
```

Finally, cluster the flows using DBSCAN.\
Adjust `eps` and `minPts` to control cluster tightness and minimum cluster size. Cluster composition is determined by these DBSCAN parameters.

```{r}
# Cluster flows using DBSCAN
flows_clustered <- cluster_flows_dbscan(dmat, wvec, flows, eps = 8, minPts = 70)

# View the first few rows of the clustered data
head(flows_clustered, 10)

# how many unique clusters were found?
length(unique(flows_clustered$cluster))

# number of flows in each cluster
flows_clustered |>
  group_by(cluster) |>
  summarise(n = n()) |>
  arrange(desc(n))
```

### Visualise

Let's take a look at the clusters

```{r}
# Keep only the biggest clusters for visualisation
flows_clustered <- flows_clustered |>
  filter(cluster != 0) |> # these are normally the noisepoints
  group_by(cluster) |>
  mutate(
    size = n(),
    count_cluster = sum(count)
  ) |>
  ungroup() |>
  filter(
    size > 7, # minimum size of cluster
    count_cluster > 100
  ) # minumum number of trips in cluster
```

Add geometry back onto the data

```{r}
# Add the geometry back onto the data
flows_clustered <- flows_sf |>
  select(flow_ID) |>
  inner_join(flows_clustered, by = "flow_ID")
```

```{r}
#| output: false

# plot
tm_shape(flows_clustered) +
  tm_lines(
    lwd = "count",
    col = "cluster",
    palette = "Accent", # YlGn
    # style = "pretty",
    alpha = 1,
    title.col = "Cluster",
    title.lwd = "No. of people",
    scale = 10,
    legend.col.show = FALSE,
    showNA = FALSE
  ) +
  tm_facets(
    by = "cluster",
    free.coords = FALSE,
    nrow = 4,
    showNA = FALSE
  ) +
  tm_layout(
    fontfamily = "Georgia",
    main.title = paste0("Clustered flows"),
    main.title.size = 1.1,
    main.title.color = "azure4",
    main.title.position = "left",
    legend.outside = TRUE,
    legend.outside.position = "bottom",
    legend.stack = "horizontal",
    # remove panel headers
    # panel.show = FALSE,
    frame = FALSE
  ) -> cluster_results

cluster_results
```

```{r}
#| echo: false
# save the tmap output
tmap_save(tm = cluster_results, filename = "man/figures/cluster_results.png", width = 8, dpi = 1080, asp = 0)
# load the saved map
```

![](man/figures/cluster_results.png)

The package also has a function to test different combinations of input parameters (`eps` and `minPts`) to see how the clustering changes. This can be useful for preliminary sensitivity analysis.

```{r}
sensitivity_results <- dbscan_sensitivity(
  flows = flows,
  dist_mat = dmat,
  options_epsilon <- c(1, 2, 5, 7.5, 9),
  options_minpts <- c(50, 75, 100, 150)
)

# show the results
head(sensitivity_results)

# number of clusters with more than five od pairs:
sensitivity_results %>%
  filter(size > 5) %>%
  group_by(id) %>%
  summarise(
    no_of_clusters = n(),
    total_count = sum(count_sum)
  ) %>%
  ungroup() %>%
  arrange(desc(no_of_clusters))
```

Let's plot the output

```{r}
#| output: false

sensitivity_results %>%
  filter(cluster != 0) %>%
  group_by(id) %>%
  mutate(clusters = n()) %>%
  # How many clusters have more than 5 od pairs in them?
  mutate(clusters = sum(size > 5)) %>%
  ungroup() %>%
  filter(clusters > 5) %>%
  ggplot(aes(x = cluster, y = size, fill = count_sum)) +
  geom_col() +
  scale_y_continuous(trans = "log10") +
  facet_wrap(~id, scales = "fixed") +
  labs(
    title = "Sensitivity analysis for clustering - Varying {eps} and {minPts}",
    subtitle = "Parameter combinations that returned more than 1 cluster",
    x = "Cluster no.",
    y = "No. of od pairs in cluster",
    fill = "No. of \ncommuters"
  ) +
  theme_bw()
```

```{r}
#| echo: false

# save the ggplot output
ggsave("man/figures/sensitivity_results.png")
# load the saved plot
```

![Size and commuter count of detected clusters across DBSCAN parameter combinations. Each facet shows results for one {eps, minPts} setting; bar height represents the number of OD pairs in a cluster (log scale), and fill indicates the total count in that OD pair](man/figures/sensitivity_results.png)

The plot shows the number of origin-destination pairs in each cluster. For each facet, each bar represents a cluster, and the height of the bar indicates the number of origin-destination pairs in that cluster. Many of the parameter (`minPts` and `eps`) combinations returned no clusters, and the combinations that did return clusters are shown in the plot. Depending on the analysis being done, you could proceed with the promising combinations, visualise them as done in the map above, and choose the one that makes the most sense to you.

## Future Work

-   [ ] Add more distance matrices (e.g. Frechet distance)
-   [ ] Add more clustering algorithms, and use a more efficient data structure as a workaround for not being able to use weights with other clustering algorithms

## References
